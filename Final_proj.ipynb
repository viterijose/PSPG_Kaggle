{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f69f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_71340\\1418472508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# TensorFlow ≥2.0 is required\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;34m\"2.0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a72e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.13\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./train.csv\")\n",
    "Y_train = pd.read_csv(\"./train_labels.csv\")\n",
    "test_full = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "#     data_dir = os.path.join(\"datasets\", \"kaggle_comp\")\n",
    "#     os.makedirs(data_dir, exist_ok=True)\n",
    "#     path_format = os.path.join(data_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "#     filepaths = []\n",
    "#     m = len(data)\n",
    "#     for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "#         part_csv = path_format.format(name_prefix, file_idx)\n",
    "#         filepaths.append(part_csv)\n",
    "#         with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "#             if header is not None:\n",
    "#                 f.write(header)\n",
    "#                 f.write(\"\\n\")\n",
    "#             for row_idx in row_indices:\n",
    "#                 f.write(\",\".join([repr(col) for col in data.loc[row_idx]]))\n",
    "#                 f.write(\"\\n\")\n",
    "#     return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce memory\n",
    "def reduce_memory(df):   \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "        \n",
    "        #Only focuses on numerical data (categorical data is handled later)\n",
    "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')): #DateTime object and Category object\n",
    "            if (col_type != 'object'): #Object type\n",
    "                col_min = df[col].min()\n",
    "                col_max = df[col].max()\n",
    "\n",
    "                #Only focuses on if the type of the attribute is of type 'int'\n",
    "                # np.iinfo() finds the Machine Limits for the data type\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    #Case 1: If the Machine Limits of the attribute fall between those of type int8\n",
    "                    if col_min > np.iinfo(np.int8).min and col_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8) #Changes the type to int8\n",
    "                    #Case 2: If the Machine Limits of the attribute fall between those of type int16\n",
    "                    elif col_min > np.iinfo(np.int16).min and col_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16) #Changes the type to int16\n",
    "                    #Case 3: If the Machine Limits of the attribute fall between those of type int32\n",
    "                    elif col_min > np.iinfo(np.int32).min and col_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32) #Changes the type to int32\n",
    "                    #Case 4: If the Machine Limits of the attribute fall between those of type int64\n",
    "                    elif col_min > np.iinfo(np.int64).min and col_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64) #Changes the type to int64\n",
    "\n",
    "                #Only focuses on if the type of the attribute is of type 'float'\n",
    "                # np.finfo() finds the Machine Limits for the data type\n",
    "                else:\n",
    "                    #Case 1: If the Machine Limits of the attribute fall between those of type float16\n",
    "                    if col_min > np.finfo(np.float16).min and col_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    #Case 1: If the Machine Limits of the attribute fall between those of type float32\n",
    "                    elif col_min > np.finfo(np.float32).min and col_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    #All other cases doesn;t change\n",
    "                    else:\n",
    "                        pass\n",
    "            \n",
    "            #If the attribute is an object than it will change its type to category\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61dc5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = reduce_memory(X_train)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803caffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77251d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49762df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = reduce_memory(Y_train)\n",
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5654a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['user_id']=labels_df.session_id.str.split(\"_\", expand = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0561e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c251e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"level\"] = labels_df.session_id.str.split(\"_\", expand = True)[1]\n",
    "labels_df[\"level\"] = labels_df[\"level\"].apply(lambda x : re.sub(\"\\D\", \"\",x)) \n",
    "labels_df[\"level\"] = pd.to_numeric(labels_df[\"level\"])\n",
    "labels_df[\"user_id\"] = pd.to_numeric(labels_df[\"user_id\"])\n",
    "labels_df[\"session_level\"] = labels_df[\"level\"].apply(lambda x: 0 if x <= 4 else 1 if x >= 5 and x <= 12 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb00c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions 1-4 belong to level 1, 5-12 to level 2, 13 - 22 to level 3\n",
    "labels_df.level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ea356",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique users: \",len(labels_df.user_id.unique()))\n",
    "print(\"Number of unique sessions: \",len(labels_df.session_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d80e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skipping this for now, it is generating issues on the csv, adding a new column randomly in random rows\n",
    "# header_cols = X_train.columns\n",
    "# header = \",\".join(header_cols)\n",
    "# train_filepaths = save_to_multiple_csv_files(X_train, \"train\", header, n_parts=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3ea530",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_names = ['session_id', 'index', 'elapsed_time', 'level',\n",
    "       'page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "       'hover_duration', 'fullscreen', 'hq', 'music']\n",
    "numeric_features = train_df[numeric_feature_names].copy()\n",
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the data described in the notebook, this is an MNAR type, meaning, the value is missing not at random \n",
    "numeric_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features.shape,labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a243a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numeric_features['session_id'].unique()),len(Y_train['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features['hover_duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13230025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generating new data based on the users average time per level\n",
    "# def time_per_level(data,users_id):\n",
    "#     res = pd.DataFrame([])\n",
    "#     filtered_features =[]\n",
    "#     for user in users_id:\n",
    "#         for level in range(23):\n",
    "#             filtered_features = data[(data['session_id'] == user ) & (data['level'] == level)]\n",
    "#             avg_time = filtered_features['elapsed_time'].mean()\n",
    "#             res = pd.concat([res, pd.DataFrame({'time_per_level': [avg_time],'user_id':user,'level':level})], ignore_index=True)\n",
    "#     return res\n",
    "# val = time_per_level(X_train,Y_train.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652026be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of my labels so I can modify the column names and keep the raw dataset intact\n",
    "labels_df_cp= labels_df.copy()\n",
    "labels_df_cp.rename(columns = {'session_id':'session_res','user_id':'session_id'}, inplace = True)\n",
    "labels_df_cp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd414830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no level 0 in the training labels provided, how should we handle this?\n",
    "train_df_cp = train_df.copy()\n",
    "df_full = pd.merge(train_df_cp, labels_df_cp, how='inner',on=['session_id','level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cf3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fa503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_group_level(q):\n",
    "#     qno = int(q[1:])\n",
    "#     if qno < 4:\n",
    "#         return '0-4'\n",
    "#     elif qno < 14:\n",
    "#         return '5-12'\n",
    "#     return '13-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dcf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label['q'] = train_label['session_id'].apply(lambda s: s.split(\"_\")[-1])\n",
    "# train_label['level_group'] = train_label.q.apply(get_group_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_full[['elapsed_time', 'fullscreen','room_coor_x','room_coor_y','screen_coor_x',\n",
    "                    'screen_coor_y','hover_duration']])\n",
    "training_data_scaled = scaler.transform(df_full[['elapsed_time', 'fullscreen','room_coor_x','room_coor_y','screen_coor_x',\n",
    "                                                 'screen_coor_y','hover_duration']])\n",
    "training_data_scaled = pd.DataFrame(df_full, columns=['elapsed_time_scaled', 'fullscreen_scaled','room_coor_x_scaled',\n",
    "                                                      'room_coor_y_scaled','screen_coor_x_scaled','screen_coor_y_scaled',\n",
    "                                                      'hover_duration_scaled'])\n",
    "df_full = pd.concat([df_full, training_data_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset shape: ',df_full.shape,'\\n')\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data=df_full[['elapsed_time_scaled','fullscreen_scaled']].copy()\n",
    "# label_data=df_full[['correct']].copy()\n",
    "# training_data.info(),label_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9066a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de182a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.fit(test[['elapsed_time', 'fullscreen']])\n",
    "# test_data_scaled = scaler.transform(test[['elapsed_time', 'fullscreen']])\n",
    "# test_data_scaled = pd.DataFrame(test, columns=['elapsed_time_scaled', 'fullscreen_scaled'])\n",
    "# test = pd.concat([test, test_data_scaled], axis=1)\n",
    "# test_data=test[['elapsed_time_scaled','fullscreen_scaled']].copy()\n",
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388f7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=df_full[['elapsed_time_scaled','fullscreen_scaled']]\n",
    "label_data=df_full[['correct']]\n",
    "print('Training data shape: ',training_data.shape,'\\n','Label data shape: ',label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val = training_data[:int(len(training_data)*.8)],training_data[int(len(training_data)*.8):]\n",
    "y_train,y_val = label_data[:int(len(label_data)*.8)],label_data[int(len(label_data)*.8):]\n",
    "print('X train shape: ',x_train.shape,'\\n','X valid shape: ',x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa621ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(2,),activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c850a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a221906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.loc[2,['elapsed_time','fullscreen']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = test.loc[2,['elapsed_time','fullscreen']].values\n",
    "# X_new = X_new.astype('float32')\n",
    "# y_proba = model.predict(X_new.reshape(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c52942",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jo_wilder.competition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjo_wilder\u001b[39;00m\n\u001b[0;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m jo_wilder\u001b[38;5;241m.\u001b[39mmake_env()\n\u001b[0;32m      3\u001b[0m iter_test \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39miter_test()\n",
      "File \u001b[1;32m~\\Documents\\Deep Learning\\Final_project\\jo_wilder\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompetition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_env\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmake_env\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jo_wilder.competition'"
     ]
    }
   ],
   "source": [
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feee4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "# for (test, sample_submission) in iter_test:\n",
    "    \n",
    "#     dummies = pd.get_dummies(test['event_name'])\n",
    "#     test = pd.concat([test, dummies], axis=1)\n",
    "#     df = feature_engineer(test)\n",
    "#     grp = test.level_group.values[0]\n",
    "#     a,b = limits[grp]\n",
    "#     for t in range(a,b):\n",
    "#         clf = models[f'{grp}_{t}']\n",
    "#         p = clf.predict_proba(df[FEATURES].astype('float32'))[:,1]\n",
    "#         pint = [int(x>best_threshold) for x in p ]\n",
    "#         mask = sample_submission.session_id.str.endswith(f'q{t}')\n",
    "#         sample_submission.loc[mask,'correct'] = pint\n",
    "    \n",
    "#     env.predict(sample_submission)\n",
    "\n",
    "# print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf74a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
